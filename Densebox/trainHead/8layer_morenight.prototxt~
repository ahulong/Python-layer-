name: "ClsRegNet"

#-------------------------------------------
layer {
  name: "data"
  type: 'Python'
  top: "data"
  top: "dlabel"
  top: "ylabel"
  top: "mlabel"
  include{
          phase:TRAIN
   }
   python_param {
     module: "Headtraindata"
     layer: "TrData"
     param_str: "/mnt/data1/hxw/caffe/imgwithbox_v3/"
  }
}


layer {
  name: "data"
  type: 'Python'
  top: "data"
  top: "dlabel"
  top: "ylabel"
  top: "mlabel"
   include {
    phase: TEST
   }  
   python_param {
    module: "Headtestdata"
    layer: "TeData"
    #param_str: "/home/apollo/Workspace/user/caffe/imgwithbox_v1/"
    param_str: "/mnt/data1/hxw/caffe/imgwithbox_v3/"
  }
}



#Layer 1------ -------------------------------------------
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
      name: "relu1_1"
      type: "ReLU"
      bottom: "conv1_1"
      top: "conv1_1"
}


layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#Layer 2-------------------------------------------------
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
    name: "relu2_1"
    type: "ReLU"
    bottom: "conv2_1"
    top: "conv2_1"
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
#64*16*16


#Layer 3-------------------------------------------------
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#128*8*8

#Layer 4-------------------------------------------------
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}

#256*4*4=8192
# upsampling layer-----------
layer {
        name: "upsample1"
        type: "Deconvolution"
        bottom: "conv4_1" 
        top: "upsample1"
        convolution_param {
                 kernel_size: 2
                 stride: 2
                 num_output: 512
                 group: 512
                 pad: 0
                 weight_filler: { type: "bilinear" }
                 bias_term: false
                 }   
}


layer {
  name: "Concat_upsampling"
  type: "Concat"
  bottom: "conv3_1"
  bottom: "upsample1"
  top: "Concat_upsampling"
  concat_param {
    concat_dim: 1
  }
}

#Layer detection loss --------------
layer {
  name: "conv5_1_det"
  type: "Convolution"
  bottom: "Concat_upsampling"
  top: "conv5_1_det"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "relu5_1_det"
  type: "ReLU"
  bottom: "conv5_1_det"
  top: "conv5_1_det"
}

layer {
  name: "dropdet"
  type: "Dropout"
  bottom: "conv5_1_det"
  top: "conv5_1_det"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "conv5_2_det"
  type: "Convolution"
  bottom: "conv5_1_det"
  top: "conv5_2_det"
  param {
    lr_mult: 1
    decay_mult: 1
  }

  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}



#Layer regression loss--------------
layer {
  name: "conv5_1_loc"
  type: "Convolution"
  bottom: "Concat_upsampling"
  top: "conv5_1_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "relu5_1_loc"
  type: "ReLU"
  bottom: "conv5_1_loc"
  top: "conv5_1_loc"
}
layer {
  name: "droploc"
  type: "Dropout"
  bottom: "conv5_1_loc"
  top: "conv5_1_loc"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "conv5_2_loc"
  type: "Convolution"
  bottom: "conv5_1_loc"
  top: "conv5_2_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}




#loss layer-------------------------------------------------
layer {
  name: "denseloss"
  type: 'Python'
  top: "loss"
  bottom: "conv5_2_det"
  bottom: "conv5_2_loc"
  bottom: "dlabel"
  bottom: "ylabel"
  bottom: "mlabel"
  python_param {
    module: "Headloss"
    layer: "denloss"  
  }
  loss_weight: 1
  
}



